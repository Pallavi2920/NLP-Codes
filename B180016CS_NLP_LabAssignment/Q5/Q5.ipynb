{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d782752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Query: Which bat has handle?\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/Users/pallavi.gtide.co/nltk_data'\n    - '/Users/pallavi.gtide.co/opt/anaconda3/nltk_data'\n    - '/Users/pallavi.gtide.co/opt/anaconda3/share/nltk_data'\n    - '/Users/pallavi.gtide.co/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/Users/pallavi.gtide.co/nltk_data'\n    - '/Users/pallavi.gtide.co/opt/anaconda3/nltk_data'\n    - '/Users/pallavi.gtide.co/opt/anaconda3/share/nltk_data'\n    - '/Users/pallavi.gtide.co/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/18/0gt00wxs1nj87mmpljftvpph0000gq/T/ipykernel_88691/171366792.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0msent32_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mfiltered_sent1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimpleFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mfiltered_sent2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimpleFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mfiltered_sent3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimpleFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/18/0gt00wxs1nj87mmpljftvpph0000gq/T/ipykernel_88691/171366792.py\u001b[0m in \u001b[0;36msimpleFilter\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mfiltered_sent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;31m# for i in synonymsCreator(w):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m#   filtered_sent.append(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/Users/pallavi.gtide.co/nltk_data'\n    - '/Users/pallavi.gtide.co/opt/anaconda3/nltk_data'\n    - '/Users/pallavi.gtide.co/opt/anaconda3/share/nltk_data'\n    - '/Users/pallavi.gtide.co/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import codecs\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "\n",
    "# Remove Stop Words . Word Stemming . Return new tokenised list.\n",
    "\n",
    "def filteredSentence(sentence):\n",
    "\n",
    "    filtered_sent = []\n",
    "    lemmatizer = WordNetLemmatizer()  # lemmatizes the words\n",
    "    ps = PorterStemmer()  # stemmer stems the root of the word.\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(sentence)\n",
    "\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(lemmatizer.lemmatize(ps.stem(w)))\n",
    "            for i in synonymsCreator(w):\n",
    "                filtered_sent.append(i)\n",
    "    return filtered_sent\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "# Add synonyms to match list\n",
    "\n",
    "def synonymsCreator(word):\n",
    "    synonyms = []\n",
    "\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for i in syn.lemmas():\n",
    "            synonyms.append(i.name())\n",
    "\n",
    "    return synonyms\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "# Cehck and return similarity\n",
    "\n",
    "def simlilarityCheck(word1, word2):\n",
    "\n",
    "    word1 = word1 + \".n.01\"\n",
    "    word2 = word2 + \".n.01\"\n",
    "    try:\n",
    "        w1 = wordnet.synset(word1)\n",
    "        w2 = wordnet.synset(word2)\n",
    "\n",
    "        return w1.wup_similarity(w2)\n",
    "\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "\n",
    "def simpleFilter(sentence):\n",
    "\n",
    "    filtered_sent = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(sentence)\n",
    "\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(lemmatizer.lemmatize(w))\n",
    "            # for i in synonymsCreator(w):\n",
    "            # \tfiltered_sent.append(i)\n",
    "    return filtered_sent\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    cricfile = codecs.open(\"cricketbat.txt\", 'r', \"utf-8\")\n",
    "    sent2 = cricfile.read().lower()\n",
    "    vampirefile = codecs.open(\"vampirebat.txt\", 'r', 'utf-8')\n",
    "    sent1 = vampirefile.read().lower()\n",
    "    sent3 = \"start\"\n",
    "\n",
    "    # FOR TEST , replace the above variables with below sent1 and sent 2\n",
    "    # sent1 = \"the commercial banks are used for finance. all the financial matters are managed by financial banks and they have lots of money, user accounts like salary account and savings account, current account. money can also be withdrawn from this bank.\"\n",
    "    # sent2 = \"the river bank has water in it and it has fishes trees . lots of water is stored in the banks. boats float in it and animals come and drink water from it.\"\n",
    "    # sent3 = \"from which bank should i withdraw money\"\n",
    "\n",
    "    while(sent3 != \"end\"):\n",
    "\n",
    "        sent3 = input(\"Enter Query: \").lower()\n",
    "\n",
    "        filtered_sent1 = []\n",
    "        filtered_sent2 = []\n",
    "        filtered_sent3 = []\n",
    "\n",
    "        counter1 = 0\n",
    "        counter2 = 0\n",
    "        sent31_similarity = 0\n",
    "        sent32_similarity = 0\n",
    "\n",
    "        filtered_sent1 = simpleFilter(sent1)\n",
    "        filtered_sent2 = simpleFilter(sent2)\n",
    "        filtered_sent3 = simpleFilter(sent3)\n",
    "\n",
    "        for i in filtered_sent3:\n",
    "\n",
    "            for j in filtered_sent1:\n",
    "                counter1 = counter1 + 1\n",
    "                sent31_similarity = sent31_similarity + simlilarityCheck(i, j)\n",
    "\n",
    "            for j in filtered_sent2:\n",
    "                counter2 = counter2 + 1\n",
    "                sent32_similarity = sent32_similarity + simlilarityCheck(i, j)\n",
    "\n",
    "        filtered_sent1 = []\n",
    "        filtered_sent2 = []\n",
    "        filtered_sent3 = []\n",
    "\n",
    "        filtered_sent1 = filteredSentence(sent1)\n",
    "        filtered_sent2 = filteredSentence(sent2)\n",
    "        filtered_sent3 = filteredSentence(sent3)\n",
    "\n",
    "        sent1_count = 0\n",
    "        sent2_count = 0\n",
    "\n",
    "        for i in filtered_sent3:\n",
    "\n",
    "            for j in filtered_sent1:\n",
    "\n",
    "                if(i == j):\n",
    "                    sent1_count = sent1_count + 1\n",
    "\n",
    "            for j in filtered_sent2:\n",
    "                if(i == j):\n",
    "                    sent2_count = sent2_count + 1\n",
    "\n",
    "        if((sent1_count + sent31_similarity) > (sent2_count+sent32_similarity)):\n",
    "            print(\"Mammal Bat\")\n",
    "        else:\n",
    "            print(\"Cricket Bat\")\n",
    "\n",
    "        # -----------------------------------------------\n",
    "        # Sentence1: the river bank has water in it and it has fishes trees . lots of water is stored in the banks. boats float in it and animals come and drink water from it.\n",
    "        # sentence2: the commercial banks are used for finance. all the financial matters are managed by financial banks and they have lots of money, user accounts like salary account and savings account, current account. money can also be withdrawn from this bank.\n",
    "        # query: from which bank should i withdraw money.\n",
    "\n",
    "        # sen1: any of various nocturnal flying mammals of the order Chiroptera, having membranous wings that extend from the forelimbs to the hind limbs or tail and anatomical adaptations for echolocation, by which they navigate and hunt prey.\n",
    "        # sen 2: a cricket wooden bat is used for playing criket. it is rectangular in shape and has handle and is made of wood or plastic and is used by cricket players.\n",
    "    print(\"\\nTERMINATED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "441c9ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/pallavi.gtide.co/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6591f41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Query: Which bat has handle?\n",
      "Cricket Bat\n",
      "Enter Query: Which bat can fly?\n",
      "Mammal Bat\n",
      "Enter Query: Bat that can see\n",
      "Mammal Bat\n",
      "Enter Query: bat used to play cricket\n",
      "Cricket Bat\n",
      "Enter Query: bat gives birth\n",
      "Mammal Bat\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import codecs\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "\n",
    "# Remove Stop Words . Word Stemming . Return new tokenised list.\n",
    "\n",
    "def filteredSentence(sentence):\n",
    "\n",
    "    filtered_sent = []\n",
    "    lemmatizer = WordNetLemmatizer()  # lemmatizes the words\n",
    "    ps = PorterStemmer()  # stemmer stems the root of the word.\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(sentence)\n",
    "\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(lemmatizer.lemmatize(ps.stem(w)))\n",
    "            for i in synonymsCreator(w):\n",
    "                filtered_sent.append(i)\n",
    "    return filtered_sent\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "# Add synonyms to match list\n",
    "\n",
    "def synonymsCreator(word):\n",
    "    synonyms = []\n",
    "\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for i in syn.lemmas():\n",
    "            synonyms.append(i.name())\n",
    "\n",
    "    return synonyms\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "# Cehck and return similarity\n",
    "\n",
    "def simlilarityCheck(word1, word2):\n",
    "\n",
    "    word1 = word1 + \".n.01\"\n",
    "    word2 = word2 + \".n.01\"\n",
    "    try:\n",
    "        w1 = wordnet.synset(word1)\n",
    "        w2 = wordnet.synset(word2)\n",
    "\n",
    "        return w1.wup_similarity(w2)\n",
    "\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "\n",
    "def simpleFilter(sentence):\n",
    "\n",
    "    filtered_sent = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(sentence)\n",
    "\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(lemmatizer.lemmatize(w))\n",
    "            # for i in synonymsCreator(w):\n",
    "            # \tfiltered_sent.append(i)\n",
    "    return filtered_sent\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    cricfile = codecs.open(\"cricketbat.txt\", 'r', \"utf-8\")\n",
    "    sent2 = cricfile.read().lower()\n",
    "    vampirefile = codecs.open(\"vampirebat.txt\", 'r', 'utf-8')\n",
    "    sent1 = vampirefile.read().lower()\n",
    "    sent3 = \"start\"\n",
    "\n",
    "    # FOR TEST , replace the above variables with below sent1 and sent 2\n",
    "    # sent1 = \"the commercial banks are used for finance. all the financial matters are managed by financial banks and they have lots of money, user accounts like salary account and savings account, current account. money can also be withdrawn from this bank.\"\n",
    "    # sent2 = \"the river bank has water in it and it has fishes trees . lots of water is stored in the banks. boats float in it and animals come and drink water from it.\"\n",
    "    # sent3 = \"from which bank should i withdraw money\"\n",
    "\n",
    "    while(sent3 != \"end\"):\n",
    "\n",
    "        sent3 = input(\"Enter Query: \").lower()\n",
    "\n",
    "        filtered_sent1 = []\n",
    "        filtered_sent2 = []\n",
    "        filtered_sent3 = []\n",
    "\n",
    "        counter1 = 0\n",
    "        counter2 = 0\n",
    "        sent31_similarity = 0\n",
    "        sent32_similarity = 0\n",
    "\n",
    "        filtered_sent1 = simpleFilter(sent1)\n",
    "        filtered_sent2 = simpleFilter(sent2)\n",
    "        filtered_sent3 = simpleFilter(sent3)\n",
    "\n",
    "        for i in filtered_sent3:\n",
    "\n",
    "            for j in filtered_sent1:\n",
    "                counter1 = counter1 + 1\n",
    "                sent31_similarity = sent31_similarity + simlilarityCheck(i, j)\n",
    "\n",
    "            for j in filtered_sent2:\n",
    "                counter2 = counter2 + 1\n",
    "                sent32_similarity = sent32_similarity + simlilarityCheck(i, j)\n",
    "\n",
    "        filtered_sent1 = []\n",
    "        filtered_sent2 = []\n",
    "        filtered_sent3 = []\n",
    "\n",
    "        filtered_sent1 = filteredSentence(sent1)\n",
    "        filtered_sent2 = filteredSentence(sent2)\n",
    "        filtered_sent3 = filteredSentence(sent3)\n",
    "\n",
    "        sent1_count = 0\n",
    "        sent2_count = 0\n",
    "\n",
    "        for i in filtered_sent3:\n",
    "\n",
    "            for j in filtered_sent1:\n",
    "\n",
    "                if(i == j):\n",
    "                    sent1_count = sent1_count + 1\n",
    "\n",
    "            for j in filtered_sent2:\n",
    "                if(i == j):\n",
    "                    sent2_count = sent2_count + 1\n",
    "\n",
    "        if((sent1_count + sent31_similarity) > (sent2_count+sent32_similarity)):\n",
    "            print(\"Mammal Bat\")\n",
    "        else:\n",
    "            print(\"Cricket Bat\")\n",
    "\n",
    "        # -----------------------------------------------\n",
    "        # Sentence1: the river bank has water in it and it has fishes trees . lots of water is stored in the banks. boats float in it and animals come and drink water from it.\n",
    "        # sentence2: the commercial banks are used for finance. all the financial matters are managed by financial banks and they have lots of money, user accounts like salary account and savings account, current account. money can also be withdrawn from this bank.\n",
    "        # query: from which bank should i withdraw money.\n",
    "\n",
    "        # sen1: any of various nocturnal flying mammals of the order Chiroptera, having membranous wings that extend from the forelimbs to the hind limbs or tail and anatomical adaptations for echolocation, by which they navigate and hunt prey.\n",
    "        # sen 2: a cricket wooden bat is used for playing criket. it is rectangular in shape and has handle and is made of wood or plastic and is used by cricket players.\n",
    "    print(\"\\nTERMINATED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87e936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
